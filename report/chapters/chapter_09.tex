%!TEX root = ../risk_book.tex

\chapter{Limitations of the study}

	Our methodology was innovative, and involved fitting theories, practices and tools together in novel ways. Through the course of our investigation we noted two major clusters of limitations. The first were issues relating to the performance and epistemological consequences of digital tools used during the investigation. In short, available digital tools may not perform as desired. In the case of parsers, this is generally an incorrect parse. 

	%	%\noindent Also an issue is that Stanford CoreNLP uses phrase structure and dependency grammars, rather than SFG (for which fewer computational resources are presently available). We were thus left with the task of translating systemic ideas into phrase structure grammar and dependency grammar. This process was often time-consuming and counter-intuitive, as well as theoretically difficult to reconcile. In the case of topic modelling, rather than erroneous, results may simply be unhelpful. The modeller is blind to grammatical structure as well as the division of language into three metafunctions. Accordingly, MALLET groups texts based on words that are unlikely to contribute not contribute to the semantic field of the text (\emph{like, please, to, having, could}). Furthermore, MALLET's conceptualisation of topic may differ markedly from a human reader's: in one iteration of the topic modelling, MALLET grouped together articles about African American religious issues and chess, apparently based on the co-occurrence of words like \emph{black}, \emph{white}, \emph{saving} and \emph{bishop}.

	The second major issue unearthed during the investigation concerned the size of the dataset, which, aside from being simply computationally intensive, was also so large that it constrained the kinds of analytical methods available to us. With 29 annual subcorpora, as well as three topic subcorpora, we struggled to simultaneously maintain a focus on minute changes in lexicogrammar and to connect change generally to events of interest to sociologists. Indeed, though instantiations of risk words may react to current events, further subdivision of the corpus into weekly/monthly subcorpora proved too unwieldy. A similar investigation could be carried out on one subcorpus alone, divided into weeks or months, in order to better assess the influence of individual events. The richness of the data also prevented direct comparison of more risk fields, with only a cursory treatment of government and health risks given here. A final issue caused by issues of data size was that we were unable to manually check each

	 Search query output was manually read to determine that the correct features were being located. What was missing as a result of parsing problems or query design likely went unnoticed amongst the streams of text. By the conclusion of the interrogation, millions of clauses had been manipulated, millions of features extracted and counted---mistakes are unfortunately bound to remain.

\section{The limits of lexicogrammatical querying}

		~\ \todo[inline,color=green!40]{\noindent Discuss how our investigation focusses more or less on congruent realisations, and is monomodal...}

\section{Conclusions}

    Instantiation of risk words is linked to real-world events: the beginnings of the AIDS epidemic are accompanied by a spike in health risk discourse; 9\slash 11 appears to be a catalyst for increasing discussion of risks and threats of terror and war. It remains very difficult, however, to fully disentangle the constructive-responsive relationship between real-world events and instantiation of particular concepts in language. Broader ideologies and social movements may indeed be more reliable predictors of linguistic change.

    \begin{itemize}
    \item We found that it is very difficult to pinpoint the effect of individual events on risk word usage in the NYT as a whole.
        \item Our interrogation of economics, health and politics articles turned up clearer evidence of the effect of real events.
        \item Even so, our approach to the creation of the subcorpora was simple, and the topics were very broad. Manually selection of automatically located articles for more specific topics would likely result in clearer indications of the effects of events on risk word usage.
        \item The main thrust of our approach was to investigate the sum total of NYT articles during the sampling years.
        \item While political risks peaked during US election times, this could not be observed when analysing the corpus as a whole.
        \item Accordingly, our findings pointed more toward the influence of broader social movements than to specific events.
        \item We interpreted many of the changes in the behaviour of risk words as evidence for \textbf{neoliberalism} and \textbf{reflexive modernity}.
        \item Indeed, the corpus developed for this study could be reused in a multitude of ways to 
        \item Finally, it must be borne in mind that the NYT is merely one newspaper, and newspapers are merely one genre
        \item We selected NYT for its size, consistency, the availability of digitised content, and its influence in global discourse.
        \item Most obviously, the emergence of the Web challenges this set of criteria in a number of ways. Popular social networks, as well as the public web, produce exponentially more content than a single newspaper.
        \item Mining global news or blog posts via RSS feeds, or Tweets via the Twitter API, allows the quantitative analysis of voices typically marginalised or absent within mainstream media.
    \end{itemize}
    
%\bibliography{../../references/libwin}